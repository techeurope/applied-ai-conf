#!/usr/bin/env node
/**
 * generate-image.mjs - CLI tool for generating game assets using AI
 *
 * Usage:
 *   node scripts/generate-image.mjs --prompt "description" [options]
 *
 * Options:
 *   --prompt, -p      Image description (required)
 *   --model, -m       Model to use: flux2, p-image (default: flux2)
 *   --input, -i       Input image path for editing (optional, enables edit mode)
 *   --output, -o      Output filename (default: auto-generated timestamp)
 *   --aspect, -a      Aspect ratio: 1:1, 16:9, 9:16, 4:3, 3:4 (default: 16:9)
 *   --seed, -s        Seed for reproducibility (default: random)
 *   --template, -t    Use composition template (auto-crops to safe zone)
 *   --help, -h        Show this help message
 *
 * Models:
 *   flux2    - fal.ai Flux 2 Turbo (default)
 *              t2i: fal-ai/flux-2/turbo
 *              edit: fal-ai/flux-2/turbo/edit
 *   p-image  - RunPod p-image
 *              t2i: pruna/p-image-t2i
 *              edit: pruna/p-image-edit
 *
 * Examples:
 *   node scripts/generate-image.mjs --prompt "cyberpunk AI datacenter"
 *   node scripts/generate-image.mjs -p "futuristic lab" -m p-image
 *   node scripts/generate-image.mjs -p "add neon glow" -i source.jpg
 *   node scripts/generate-image.mjs -p "compact voice module" -t
 *
 * Environment:
 *   FAL_API_KEY (for flux2)
 *   RUNPOD_API_KEY (for p-image)
 */

import dotenv from "dotenv";
import { fal } from "@ai-sdk/fal";
import { runpod } from "@runpod/ai-sdk-provider";
import { generateImage } from "ai";
import { writeFileSync, readFileSync, existsSync, mkdirSync } from "fs";
import { dirname, join, resolve, extname } from "path";
import { fileURLToPath } from "url";
import sharp from "sharp";

const __dirname = dirname(fileURLToPath(import.meta.url));
const projectRoot = resolve(__dirname, "..");

// Load env from project root
const envLocalPath = join(projectRoot, ".env.local");
const envPath = join(projectRoot, ".env");
if (existsSync(envLocalPath)) {
  dotenv.config({ path: envLocalPath, quiet: true });
} else {
  dotenv.config({ path: envPath, quiet: true });
}

const VALID_ASPECTS = ["1:1", "16:9", "9:16", "4:3", "3:4"];
const VALID_MODELS = ["flux2", "p-image"];

// Composition template configuration (must match create-composition-template.mjs)
const TEMPLATE_CONFIG = {
  path: "public/assets/templates/composition-template.png",
  width: 1920,
  height: 1080,
  padding: 15, // percentage
  // Computed safe zone bounds (15% padding on 1920x1080)
  safeX: 288,
  safeY: 162,
  safeWidth: 1344,
  safeHeight: 756,
};

const MODEL_CONFIG = {
  flux2: {
    provider: "fal",
    t2i: "fal-ai/flux-2/turbo",
    edit: "fal-ai/flux-2/turbo/edit",
    envKey: "FAL_API_KEY",
    supportsEdit: true,
  },
  "p-image": {
    provider: "runpod",
    t2i: "pruna/p-image-t2i",
    edit: "pruna/p-image-edit",
    envKey: "RUNPOD_API_KEY",
    supportsEdit: true,
  },
};

function showHelp() {
  console.log(`
generate-image.mjs - Generate game assets using AI

USAGE:
  node scripts/generate-image.mjs --prompt "description" [options]

OPTIONS:
  --prompt, -p      Image description (required)
  --model, -m       Model: ${VALID_MODELS.join(", ")} (default: flux2)
  --input, -i       Input image for editing
  --output, -o      Output filename (default: auto-generated)
  --aspect, -a      Aspect ratio: ${VALID_ASPECTS.join(", ")} (default: 16:9)
  --seed, -s        Seed for reproducibility (default: random)
  --template, -t    Use composition template (auto-crops to safe zone)
  --help, -h        Show this help message

MODELS:
  flux2     fal.ai Flux 2 Turbo (FAL_API_KEY)
            - t2i: fal-ai/flux-2/turbo
            - edit: fal-ai/flux-2/turbo/edit
  p-image   RunPod p-image (RUNPOD_API_KEY)
            - t2i: pruna/p-image-t2i
            - edit: pruna/p-image-edit

TEMPLATE MODE:
  When --template is used:
  - Uses composition-template.png as input (edit mode)
  - Prompt should describe object to place in marked zone
  - Output is auto-cropped to the safe zone (removes border)
  - Adds composition instructions to prompt automatically

EXAMPLES:
  node scripts/generate-image.mjs --prompt "cyberpunk AI datacenter"
  node scripts/generate-image.mjs -p "futuristic lab" -m p-image
  node scripts/generate-image.mjs -p "compact voice synthesis module" -t
  node scripts/generate-image.mjs -p "add neon effects" -i source.jpg -m flux2

OUTPUT:
  Images are saved to public/ folder.
`);
  process.exit(0);
}

function parseArgs(args) {
  const result = {
    prompt: null,
    model: "flux2",
    input: null,
    output: null,
    aspect: "16:9",
    seed: null,
    template: false,
  };

  for (let i = 0; i < args.length; i++) {
    const arg = args[i];
    const next = args[i + 1];

    switch (arg) {
      case "--help":
      case "-h":
        showHelp();
        break;
      case "--prompt":
      case "-p":
        result.prompt = next;
        i++;
        break;
      case "--model":
      case "-m":
        result.model = next;
        i++;
        break;
      case "--input":
      case "-i":
        result.input = next;
        i++;
        break;
      case "--output":
      case "-o":
        result.output = next;
        i++;
        break;
      case "--aspect":
      case "-a":
        result.aspect = next;
        i++;
        break;
      case "--seed":
      case "-s":
        result.seed = parseInt(next, 10);
        i++;
        break;
      case "--template":
      case "-t":
        result.template = true;
        break;
    }
  }

  return result;
}

function validateArgs(args) {
  if (!args.prompt) {
    console.error("ERROR: --prompt is required\n");
    console.error("Run with --help for usage information");
    process.exit(1);
  }

  if (!VALID_MODELS.includes(args.model)) {
    console.error(`ERROR: Invalid model "${args.model}"`);
    console.error(`Valid options: ${VALID_MODELS.join(", ")}`);
    process.exit(1);
  }

  if (!VALID_ASPECTS.includes(args.aspect)) {
    console.error(`ERROR: Invalid aspect ratio "${args.aspect}"`);
    console.error(`Valid options: ${VALID_ASPECTS.join(", ")}`);
    process.exit(1);
  }

  const config = MODEL_CONFIG[args.model];

  if (!process.env[config.envKey]) {
    console.error(`ERROR: ${config.envKey} not found in environment`);
    console.error("Add it to your .env file");
    process.exit(1);
  }

  if (args.input && !existsSync(args.input)) {
    console.error(`ERROR: Input image not found: ${args.input}`);
    process.exit(1);
  }

  // Template mode validation
  if (args.template) {
    const templatePath = join(projectRoot, TEMPLATE_CONFIG.path);
    if (!existsSync(templatePath)) {
      console.error(`ERROR: Composition template not found: ${templatePath}`);
      console.error("Run: node scripts/create-composition-template.mjs");
      process.exit(1);
    }
    if (args.input) {
      console.error("ERROR: Cannot use --template with --input");
      console.error("Template mode uses the composition template as input");
      process.exit(1);
    }
  }
}

function generateFilename(output, modelName) {
  if (output) {
    if (!output.endsWith(".jpg") && !output.endsWith(".png")) {
      return output + ".jpg";
    }
    return output;
  }

  const timestamp = new Date().toISOString().replace(/[:.]/g, "-");
  return `${modelName}-${timestamp}.jpg`;
}

function imageToDataUrl(imagePath) {
  const ext = extname(imagePath).toLowerCase();
  const mimeType =
    ext === ".png"
      ? "image/png"
      : ext === ".gif"
      ? "image/gif"
      : ext === ".webp"
      ? "image/webp"
      : "image/jpeg";

  const imageBuffer = readFileSync(imagePath);
  const base64 = imageBuffer.toString("base64");
  return `data:${mimeType};base64,${base64}`;
}

function getModel(config, isEditMode) {
  const modelId = isEditMode ? config.edit : config.t2i;

  if (config.provider === "fal") {
    return fal.image(modelId);
  } else if (config.provider === "runpod") {
    return runpod.image(modelId);
  }

  throw new Error(`Unknown provider: ${config.provider}`);
}

// Composition guide text to prepend when using template mode
const TEMPLATE_PROMPT_PREFIX =
  "Place the object centered within the marked magenta rectangle boundary. " +
  "The object must fit entirely inside the rectangle. " +
  "Keep the neutral gray background outside the object. " +
  "Do not render the magenta guide lines in the final image. ";

async function cropToSafeZone(imageBuffer) {
  const { safeX, safeY, safeWidth, safeHeight } = TEMPLATE_CONFIG;

  return sharp(imageBuffer)
    .extract({
      left: safeX,
      top: safeY,
      width: safeWidth,
      height: safeHeight,
    })
    .png()
    .toBuffer();
}

async function main() {
  const args = parseArgs(process.argv.slice(2));

  if (process.argv.length <= 2) {
    showHelp();
  }

  validateArgs(args);

  const config = MODEL_CONFIG[args.model];

  // Template mode uses the composition template as input
  let inputPath = args.input;
  let effectivePrompt = args.prompt;

  if (args.template) {
    inputPath = join(projectRoot, TEMPLATE_CONFIG.path);
    effectivePrompt = TEMPLATE_PROMPT_PREFIX + args.prompt;
  }

  const isEditMode = !!inputPath && config.supportsEdit;
  const modelId = isEditMode ? config.edit : config.t2i;

  const filename = generateFilename(args.output, args.model);
  // If filename already includes "public/", use it directly, otherwise prepend "public/"
  const outputPath = filename.startsWith("public/")
    ? join(projectRoot, filename)
    : join(projectRoot, "public", filename);

  const publicDir = dirname(outputPath);
  if (!existsSync(publicDir)) {
    mkdirSync(publicDir, { recursive: true });
  }

  console.log("Generating image...");
  console.log(`  Provider: ${config.provider}`);
  console.log(`  Model: ${modelId}`);
  console.log(
    `  Mode: ${isEditMode ? "edit" : "text-to-image"}${
      args.template ? " (template)" : ""
    }`
  );
  if (args.template) {
    console.log(`  Template: ${TEMPLATE_CONFIG.path}`);
    console.log(
      `  Safe zone: ${TEMPLATE_CONFIG.safeWidth}x${TEMPLATE_CONFIG.safeHeight}`
    );
  }
  console.log(`  Prompt: "${args.prompt}"`);
  console.log(`  Aspect: ${args.aspect}`);
  if (args.input) {
    console.log(`  Input: ${args.input}`);
  }
  if (args.seed !== null) {
    console.log(`  Seed: ${args.seed}`);
  }

  try {
    const options = {
      model: getModel(config, isEditMode),
      prompt: effectivePrompt,
      aspectRatio: args.aspect,
    };

    if (args.seed !== null) {
      options.seed = args.seed;
    }

    if (isEditMode) {
      const imageDataUrl = imageToDataUrl(inputPath);
      options.images = [imageDataUrl];
      // fal.ai edit models need image_urls passed via providerOptions
      if (config.provider === "fal") {
        options.providerOptions = {
          fal: {
            image_urls: [imageDataUrl],
          },
        };
      }
    }

    const { image } = await generateImage(options);

    let finalBuffer = Buffer.from(image.uint8Array);

    // Crop to safe zone if template mode
    if (args.template) {
      console.log("\nCropping to safe zone...");
      finalBuffer = await cropToSafeZone(finalBuffer);
    }

    writeFileSync(outputPath, finalBuffer);

    console.log(`\nSaved: ${filename}`);
    console.log(`Path: public/${filename}`);
    console.log(`Size: ${(finalBuffer.length / 1024).toFixed(1)}KB`);
  } catch (err) {
    console.error("\nERROR:", err?.message || err);
    process.exit(1);
  }
}

main();
